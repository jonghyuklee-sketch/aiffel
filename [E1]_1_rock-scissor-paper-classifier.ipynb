{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기\n",
    "직접 촬영한 사진을 바탕으로 가위바위보 분류기를 만드는 프로젝트를 진행하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 만들기\n",
    "노트북의 전면 카메라를 사용하여 가위, 바위, 보 이미지를 각 100장씩 만들었습니다. 일일이 찍는 것은 어려움이 있어 구글의 teachable machine(https://teachablemachine.withgoogle.com)이라는 사이트를 활용하여 보다 이미지 데이터를 손쉽게 만들었습니다. 사이트에서 image project를 선택하면 웹캠이 구동되고 클래스별 데이터를 직접 촬영할 수 있는 화면이 나타납니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디렉토리 만들기\n",
    "프로젝트용 디렉토리인 rock_scissor_paper 및 각각의 하위디렉토리를 만들었습니다.\n",
    "\n",
    "가위 : mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "\n",
    "바위 : mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "\n",
    "보 : mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "디렉토리 확인 : ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기, Resize 하기\n",
    "techable machine 사이트를 이용하여 만든 이미지 데이터의 크기는 28x28입니다. 사이즈를 바꾸어주기 위해서 pillow 라이브러리를 설치하고 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가위, 바위, 보 이미지를 불러와서 28x28 사이즈로 변경하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이어서 가위, 바위, 보에 각각 라벨링을 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 9300 입니다.\n",
      "x_train shape: (9600, 28, 28, 3)\n",
      "y_train shape: (9600,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=9600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습용 이미지와 라벨을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계 및 학습시키기\n",
    "먼저 input_shape를 컬러 값이 들어가도록 28,28,3으로 수정을 합니다. 또한 우리는 3개의 클래스가 필요하니 Dense 레이어를 3으로 변경합니다. 후에 설계된 네트워크로 epoch를 10으로 설정 후 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 56,547\n",
      "Trainable params: 56,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.0952 - accuracy: 0.5289\n",
      "Epoch 2/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7830\n",
      "Epoch 3/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8776\n",
      "Epoch 4/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9117\n",
      "Epoch 5/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9411\n",
      "Epoch 6/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9569\n",
      "Epoch 7/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9672\n",
      "Epoch 8/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9660\n",
      "Epoch 9/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9723\n",
      "Epoch 10/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9845\n",
      "Epoch 11/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9732\n",
      "Epoch 12/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9811\n",
      "Epoch 13/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9864\n",
      "Epoch 14/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9933\n",
      "Epoch 15/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9784\n",
      "Epoch 16/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9717\n",
      "Epoch 17/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9901\n",
      "Epoch 18/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9940\n",
      "Epoch 19/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9908\n",
      "Epoch 20/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9902\n",
      "Epoch 21/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9869\n",
      "Epoch 22/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9919\n",
      "Epoch 23/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9909\n",
      "Epoch 24/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9908\n",
      "Epoch 25/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9964\n",
      "Epoch 26/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9934\n",
      "Epoch 27/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9820\n",
      "Epoch 28/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 29/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 30/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 31/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 32/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9776\n",
      "Epoch 33/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9865\n",
      "Epoch 34/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9962\n",
      "Epoch 35/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9978\n",
      "Epoch 36/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 37/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9884\n",
      "Epoch 38/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 39/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9961\n",
      "Epoch 40/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9873\n",
      "Epoch 41/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 42/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 43/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9918\n",
      "Epoch 44/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9945\n",
      "Epoch 45/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 46/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 47/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 48/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 49/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 50/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9999\n",
      "Epoch 51/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 52/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 53/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9737\n",
      "Epoch 54/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9934\n",
      "Epoch 55/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 56/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9973\n",
      "Epoch 57/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 58/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 59/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 60/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 9.2079e-04 - accuracy: 0.9999\n",
      "Epoch 61/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 62/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9859\n",
      "Epoch 63/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9840\n",
      "Epoch 64/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "Epoch 65/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 66/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 67/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 68/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 69/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 70/70\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f835c0ac950>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=64\n",
    "n_train_epoch=70\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터 또한 같은 로직으로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "10/10 - 0s - loss: 3.1647 - accuracy: 0.4600\n",
      "test_loss: 3.164748430252075 \n",
      "test_accuracy: 0.46000000834465027\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "\n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test)=load_test_data(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_epoch 값을 10~100까지 시도해봤는데 70 이후 부터는 오히려 정확도가 낮아지는 현상이 발생하였습니다. 따라서 값을 70으로 설정하였습니다.\n",
    "n_dense 또한 64를 초과하는 값은 정확도를 감소시켜서 64가 최적의 값이라 생각했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가 : 정말 솔직하게 코드 하나, 로직 하나 제대로 이해하지를 못했고 배운 것은 많지만 제가 단 하나도 소화를 하지 못한다는 것을 깨달았습니다. 하이퍼파라미터를 바꾼다고는 이해가 선행되지 않아 크게 와닿지가 않았습니다. 특히 아무리 코드를 이해하려고 해도 할 수 없어 많이 답답하였고 위 프로젝트 또한 시간을 두고 계속 반복적으로 봐야한다고 생각합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
