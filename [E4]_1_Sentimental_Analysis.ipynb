{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) 데이터로더 구성\n",
    "\n",
    "- 데이터의 중복 제거\n",
    "\n",
    "- NaN 결측치 제거\n",
    "\n",
    "- 한국어 토크나이저로 토큰화\n",
    "\n",
    "- 불용어(Stopwords) 제거\n",
    "\n",
    "- 사전word_to_index 구성\n",
    "\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knolpy를 사용할건데 미리 불용어를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복되는 데이터나 결측치를 제거해주는 함수를 생성하는데 mecab을 이용하여 한국어 토큰화 작업을 진행합니다. word_to_index를 만들 때에는 미리 정의한 pad, bos, unk, unused를 제외하고 빈도 수가 높은 단어 10,000개의 단어를 가져오는 딕셔너리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 146182, 테스트 개수: 49157\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\". format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) 모델구성을 위한 데이터 분석 및 가공\n",
    "\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "\n",
    "- 적절한 최대 문장 길이 지정\n",
    "\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969355837799927\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843536204665021\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "#패딩 추가\n",
    "\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) validation set 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation set을 먼저 구성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136182, 41)\n",
      "(136182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "X_val = X_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) 모델 구성 및 훈련 개시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM state 벡터의 차원수는 8에서 128로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,169,489\n",
      "Trainable params: 2,169,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,169,489\n",
      "Trainable params: 2,169,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(128))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 [==============================] - 9s 63us/sample - loss: 0.4576 - accuracy: 0.7596 - val_loss: 0.3463 - val_accuracy: 0.8499\n",
      "Epoch 2/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.3257 - accuracy: 0.8605 - val_loss: 0.3263 - val_accuracy: 0.8557\n",
      "Epoch 3/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.2877 - accuracy: 0.8767 - val_loss: 0.3201 - val_accuracy: 0.8579\n",
      "Epoch 4/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.2593 - accuracy: 0.8915 - val_loss: 0.3306 - val_accuracy: 0.8573\n",
      "Epoch 5/20\n",
      "136182/136182 [==============================] - 8s 56us/sample - loss: 0.2339 - accuracy: 0.9027 - val_loss: 0.3518 - val_accuracy: 0.8566\n",
      "Epoch 6/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.2117 - accuracy: 0.9136 - val_loss: 0.3598 - val_accuracy: 0.8580\n",
      "Epoch 7/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.1917 - accuracy: 0.9227 - val_loss: 0.4186 - val_accuracy: 0.8518\n",
      "Epoch 8/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.1721 - accuracy: 0.9318 - val_loss: 0.4078 - val_accuracy: 0.8504\n",
      "Epoch 9/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.1561 - accuracy: 0.9392 - val_loss: 0.4575 - val_accuracy: 0.8509\n",
      "Epoch 10/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.1401 - accuracy: 0.9451 - val_loss: 0.4440 - val_accuracy: 0.8494\n",
      "Epoch 11/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.1295 - accuracy: 0.9505 - val_loss: 0.5253 - val_accuracy: 0.8442\n",
      "Epoch 12/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.1180 - accuracy: 0.9550 - val_loss: 0.4942 - val_accuracy: 0.8493\n",
      "Epoch 13/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.1085 - accuracy: 0.9584 - val_loss: 0.6135 - val_accuracy: 0.8467\n",
      "Epoch 14/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.0990 - accuracy: 0.9623 - val_loss: 0.6802 - val_accuracy: 0.8394\n",
      "Epoch 15/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.0931 - accuracy: 0.9641 - val_loss: 0.5681 - val_accuracy: 0.8461\n",
      "Epoch 16/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.0868 - accuracy: 0.9669 - val_loss: 0.6364 - val_accuracy: 0.8413\n",
      "Epoch 17/20\n",
      "136182/136182 [==============================] - 8s 55us/sample - loss: 0.0794 - accuracy: 0.9692 - val_loss: 0.6592 - val_accuracy: 0.8396\n",
      "Epoch 18/20\n",
      "136182/136182 [==============================] - 8s 56us/sample - loss: 0.0757 - accuracy: 0.9711 - val_loss: 0.6437 - val_accuracy: 0.8411\n",
      "Epoch 19/20\n",
      "136182/136182 [==============================] - 7s 55us/sample - loss: 0.0713 - accuracy: 0.9724 - val_loss: 0.7495 - val_accuracy: 0.8417\n",
      "Epoch 20/20\n",
      "136182/136182 [==============================] - 7s 54us/sample - loss: 0.0641 - accuracy: 0.9749 - val_loss: 0.7764 - val_accuracy: 0.8405\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,322,417\n",
      "Trainable params: 2,322,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model3.add(keras.layers.GlobalMaxPooling1D())\n",
    "model3.add(keras.layers.Dense(8, activation='relu'))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 [==============================] - 10s 74us/sample - loss: 0.0625 - accuracy: 0.9759 - val_loss: 0.7916 - val_accuracy: 0.8428\n",
      "Epoch 2/20\n",
      "136182/136182 [==============================] - 9s 64us/sample - loss: 0.0542 - accuracy: 0.9793 - val_loss: 0.7945 - val_accuracy: 0.8401\n",
      "Epoch 3/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0514 - accuracy: 0.9808 - val_loss: 0.8135 - val_accuracy: 0.8402\n",
      "Epoch 4/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0481 - accuracy: 0.9817 - val_loss: 0.9101 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0445 - accuracy: 0.9828 - val_loss: 0.8818 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.8094 - val_accuracy: 0.8385\n",
      "Epoch 7/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0420 - accuracy: 0.9842 - val_loss: 0.8430 - val_accuracy: 0.8401\n",
      "Epoch 8/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0377 - accuracy: 0.9857 - val_loss: 0.9394 - val_accuracy: 0.8417\n",
      "Epoch 9/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0384 - accuracy: 0.9856 - val_loss: 0.8169 - val_accuracy: 0.8408\n",
      "Epoch 10/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0354 - accuracy: 0.9869 - val_loss: 0.9736 - val_accuracy: 0.8412\n",
      "Epoch 11/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.8853 - val_accuracy: 0.8359\n",
      "Epoch 12/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0320 - accuracy: 0.9878 - val_loss: 0.9459 - val_accuracy: 0.8408\n",
      "Epoch 13/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0322 - accuracy: 0.9876 - val_loss: 0.8783 - val_accuracy: 0.8385\n",
      "Epoch 14/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0295 - accuracy: 0.9885 - val_loss: 0.9710 - val_accuracy: 0.8373\n",
      "Epoch 15/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0265 - accuracy: 0.9897 - val_loss: 1.0393 - val_accuracy: 0.8396\n",
      "Epoch 16/20\n",
      "136182/136182 [==============================] - 10s 71us/sample - loss: 0.0267 - accuracy: 0.9899 - val_loss: 0.9197 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0261 - accuracy: 0.9900 - val_loss: 1.0206 - val_accuracy: 0.8396\n",
      "Epoch 18/20\n",
      "136182/136182 [==============================] - 9s 69us/sample - loss: 0.0249 - accuracy: 0.9903 - val_loss: 0.9896 - val_accuracy: 0.8363\n",
      "Epoch 19/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0242 - accuracy: 0.9906 - val_loss: 1.0296 - val_accuracy: 0.8410\n",
      "Epoch 20/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0233 - accuracy: 0.9911 - val_loss: 1.0224 - val_accuracy: 0.8369\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model2.add(keras.layers.MaxPooling1D(5))\n",
    "model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model2.add(keras.layers.GlobalMaxPooling1D())\n",
    "model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 [==============================] - 10s 74us/sample - loss: 0.0230 - accuracy: 0.9910 - val_loss: 1.1214 - val_accuracy: 0.8368\n",
      "Epoch 2/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0194 - accuracy: 0.9923 - val_loss: 1.1204 - val_accuracy: 0.8364\n",
      "Epoch 3/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0201 - accuracy: 0.9921 - val_loss: 1.0352 - val_accuracy: 0.8398\n",
      "Epoch 4/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0201 - accuracy: 0.9921 - val_loss: 1.0279 - val_accuracy: 0.8362\n",
      "Epoch 5/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0204 - accuracy: 0.9921 - val_loss: 1.0825 - val_accuracy: 0.8430\n",
      "Epoch 6/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0183 - accuracy: 0.9929 - val_loss: 1.0168 - val_accuracy: 0.8386\n",
      "Epoch 7/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0167 - accuracy: 0.9933 - val_loss: 1.1077 - val_accuracy: 0.8405\n",
      "Epoch 8/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0167 - accuracy: 0.9932 - val_loss: 1.0479 - val_accuracy: 0.8331\n",
      "Epoch 9/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0175 - accuracy: 0.9932 - val_loss: 1.1601 - val_accuracy: 0.8377\n",
      "Epoch 10/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0154 - accuracy: 0.9937 - val_loss: 1.2787 - val_accuracy: 0.8429\n",
      "Epoch 11/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0149 - accuracy: 0.9939 - val_loss: 1.2133 - val_accuracy: 0.8410\n",
      "Epoch 12/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0161 - accuracy: 0.9935 - val_loss: 1.0334 - val_accuracy: 0.8386\n",
      "Epoch 13/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0148 - accuracy: 0.9942 - val_loss: 1.1860 - val_accuracy: 0.8348\n",
      "Epoch 14/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0131 - accuracy: 0.9945 - val_loss: 1.2024 - val_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0134 - accuracy: 0.9947 - val_loss: 1.1278 - val_accuracy: 0.8386\n",
      "Epoch 16/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0127 - accuracy: 0.9947 - val_loss: 1.1321 - val_accuracy: 0.8360\n",
      "Epoch 17/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0138 - accuracy: 0.9944 - val_loss: 1.2100 - val_accuracy: 0.8391\n",
      "Epoch 18/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0136 - accuracy: 0.9947 - val_loss: 1.0860 - val_accuracy: 0.8399\n",
      "Epoch 19/20\n",
      "136182/136182 [==============================] - 9s 65us/sample - loss: 0.0124 - accuracy: 0.9948 - val_loss: 1.1949 - val_accuracy: 0.8343\n",
      "Epoch 20/20\n",
      "136182/136182 [==============================] - 9s 66us/sample - loss: 0.0119 - accuracy: 0.9950 - val_loss: 0.9974 - val_accuracy: 0.8363\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Loss, Accuracy 그래프 시각화\n",
    "\n",
    "학습이 끝난 모델을 테스트 셋으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49157/49157 - 3s - loss: 0.7597 - accuracy: 0.8395\n",
      "[0.7596737972666459, 0.8394939]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.21005163e-01,  4.05087732e-02,  9.40833390e-02,  9.67747569e-02,\n",
       "       -3.68815362e-02,  4.82934667e-03, -1.39623687e-01,  5.25927022e-02,\n",
       "       -1.02086037e-01,  8.83680582e-02, -1.21253900e-01,  1.54756717e-02,\n",
       "       -2.42201254e-01,  1.01795286e-01, -3.17689329e-02,  7.13486224e-02,\n",
       "        3.62348743e-02, -1.28145263e-01,  3.36258523e-02, -1.67794704e-01,\n",
       "        3.83729972e-02,  4.26819623e-02, -1.00424364e-01, -6.55174106e-02,\n",
       "        8.88161436e-02,  1.29682034e-01, -1.24914488e-02,  4.96732742e-02,\n",
       "       -2.14933418e-02, -1.79431736e-01,  7.78247714e-02, -1.05941564e-01,\n",
       "        4.32067811e-02, -1.41335145e-01, -1.33700613e-02,  6.26623258e-02,\n",
       "       -7.75781497e-02,  5.08713238e-02,  3.60164717e-02, -1.08280420e-01,\n",
       "        1.94126461e-02, -1.28092319e-01,  9.98223200e-02,  3.72096077e-02,\n",
       "       -8.77892151e-02, -7.60105103e-02,  6.50536418e-02,  5.24653979e-02,\n",
       "        1.21241763e-01,  1.33398041e-01,  1.21877909e-01,  2.00521965e-02,\n",
       "        1.07108690e-01,  9.09692645e-02,  7.73373768e-02,  1.70027297e-02,\n",
       "        1.20130554e-01, -7.76156262e-02, -4.33503240e-02,  8.90576616e-02,\n",
       "       -1.35858864e-01,  7.55012333e-02, -1.12750836e-01,  1.71996906e-01,\n",
       "        1.64230186e-02, -1.69511978e-02,  1.24021560e-01,  1.28717750e-01,\n",
       "       -7.01504126e-02, -5.56470044e-02,  3.18189524e-02,  1.63526056e-05,\n",
       "        2.07452923e-02,  1.38661712e-01, -1.16683133e-01, -7.32725039e-02,\n",
       "       -5.97947538e-02, -9.76867005e-02, -7.78176412e-02,  3.06372885e-02,\n",
       "       -5.45694605e-02, -4.90767621e-02, -8.05521384e-02,  2.14938819e-02,\n",
       "       -1.48821443e-01, -2.28827614e-02, -1.49121597e-01, -1.16243616e-01,\n",
       "        1.02606714e-01,  8.22804049e-02, -3.40449251e-02,  7.44863153e-02,\n",
       "       -1.00731403e-01, -6.21844046e-02, -1.59358039e-01,  6.82537630e-02,\n",
       "       -6.28562346e-02, -7.43435547e-02, -1.06137656e-01,  8.12799409e-02,\n",
       "        1.74200684e-01, -9.90582332e-02,  8.89102370e-02, -1.13904953e-01,\n",
       "       -1.08009651e-01,  8.34585652e-02, -3.95611450e-02, -6.73069805e-02,\n",
       "       -3.58383209e-02, -5.64032011e-02,  1.82176441e-01,  6.59212023e-02,\n",
       "       -2.71475762e-02,  1.20893111e-02,  1.01300471e-01,  7.81789869e-02,\n",
       "        4.82579209e-02, -1.11082174e-01, -1.12832844e-01, -8.28966796e-02,\n",
       "       -2.37448029e-02, -3.70170586e-02, -2.18287297e-02,  9.17652175e-02,\n",
       "        1.55833036e-01, -1.30178064e-01,  5.18982783e-02,  5.32212146e-02,\n",
       "        3.93329598e-02, -1.07317008e-01, -2.86980420e-02,  3.97243276e-02,\n",
       "        3.23991515e-02, -6.40569106e-02, -4.04350609e-02, -5.11483029e-02,\n",
       "        7.66985044e-02,  9.73286703e-02,  7.20349420e-03,  8.32745805e-02,\n",
       "        5.08846641e-02,  3.15670148e-02,  1.68736249e-01, -1.00479066e-01,\n",
       "        1.56474918e-01,  3.62895243e-02,  9.81455967e-02,  1.28629804e-01,\n",
       "        1.07754715e-01, -9.05027241e-02, -1.81143358e-01,  1.03471190e-01,\n",
       "        1.38461739e-01, -8.84115580e-04, -2.53343396e-02, -1.54416859e-01,\n",
       "       -1.08992070e-01,  1.29718147e-02,  5.59927449e-02, -1.20795146e-01,\n",
       "        1.63019985e-01,  6.54636547e-02, -2.95729470e-03, -1.81595489e-01,\n",
       "       -6.40024692e-02, -5.45895994e-02,  5.46806306e-02,  9.11486819e-02,\n",
       "        4.46492434e-02,  1.46318078e-01, -9.87711698e-02,  5.66639602e-02,\n",
       "       -1.20965257e-01, -2.51108389e-02,  9.57389250e-02, -5.77490181e-02,\n",
       "        8.15537795e-02, -1.03190549e-01,  1.40671313e-01,  1.16520025e-01,\n",
       "       -1.23102851e-01,  8.01155716e-02,  6.48923814e-02,  9.74175404e-04,\n",
       "       -1.69770703e-01,  1.17193740e-02,  2.60835569e-02, -1.52436897e-01,\n",
       "        7.75976032e-02, -6.65159896e-02,  4.24647890e-02, -1.80439070e-01,\n",
       "       -1.10962339e-01,  2.83423532e-02,  7.63189141e-03, -3.25197503e-02,\n",
       "        9.15419087e-02,  6.95742369e-02,  1.03463747e-01, -7.20679015e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('명작', 0.8614985346794128),\n",
       " ('대조', 0.8524621725082397),\n",
       " ('담아낸', 0.8462417125701904),\n",
       " ('직설', 0.8422785997390747),\n",
       " ('최고', 0.8247392177581787),\n",
       " ('여운', 0.8194774985313416),\n",
       " ('나와도', 0.8176375031471252),\n",
       " ('비포', 0.8173232078552246),\n",
       " ('깊', 0.815139889717102),\n",
       " ('재밌', 0.8124272227287292)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (8) 한국어 Word2Vec 임베딩 활용하여 성능개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj31/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.3740246 , -1.7353463 ,  3.3915305 , -2.569253  , -1.4016607 ,\n",
       "        1.4556127 ,  0.9414557 ,  1.9207907 ,  0.16471806,  0.4838317 ,\n",
       "       -0.8547181 ,  2.0879807 ,  0.86741775,  0.87539405, -0.09962013,\n",
       "        0.22928311, -1.1858722 ,  0.00858838,  1.4999928 , -0.16196461,\n",
       "       -0.35184434, -0.92390764,  1.0849575 ,  0.3025011 ,  2.7021565 ,\n",
       "       -1.0263684 ,  0.32864776, -0.76589465, -2.510981  , -0.66225356,\n",
       "        2.8434615 ,  0.50130975, -1.021874  , -1.4366034 ,  1.1110784 ,\n",
       "        0.5812605 , -0.5830406 , -0.5785423 ,  1.3634988 ,  2.3074338 ,\n",
       "       -1.4314893 ,  0.45745876,  1.1073523 , -3.2135262 , -0.2898375 ,\n",
       "       -1.1622221 ,  1.2369208 , -0.7622987 , -0.37757635,  1.1376442 ,\n",
       "        0.01065568, -0.69105595,  1.5159112 ,  1.1534518 , -1.0119992 ,\n",
       "       -0.5757404 ,  1.1349088 , -1.1289831 ,  0.13004152,  2.0451715 ,\n",
       "       -0.23940353,  1.3604902 ,  0.72700524,  0.32545742,  1.0612459 ,\n",
       "        0.42252553,  1.1442151 ,  2.8774905 ,  2.4377263 , -1.340305  ,\n",
       "        0.12629706, -0.07772489, -0.59053177, -0.19007324,  0.1396541 ,\n",
       "       -1.8655105 ,  0.9401054 ,  0.5150856 ,  0.7795373 , -0.86505556,\n",
       "        0.11842118, -1.8303713 ,  1.337177  , -1.0102932 , -0.37180334,\n",
       "        0.00893255, -0.49141577, -1.05802   , -2.5987291 ,  0.9731856 ,\n",
       "        0.34080654, -2.5973568 ,  1.0046519 , -1.3914212 , -0.6504351 ,\n",
       "       -0.9010805 , -1.1341541 ,  0.75565654,  1.2941337 ,  0.0880572 ,\n",
       "       -1.0341461 , -0.1750075 , -0.01880708, -1.0835075 , -2.0333962 ,\n",
       "        1.1372623 ,  1.0626172 , -1.8369784 , -2.2662086 , -3.382057  ,\n",
       "        1.6751666 , -0.2988223 , -0.25563756, -1.5594274 ,  0.6313433 ,\n",
       "       -1.2667153 , -1.6857744 , -1.0949599 ,  0.7742313 , -0.6095523 ,\n",
       "        3.19503   ,  0.13200459,  1.7937473 , -2.8782516 ,  1.3821276 ,\n",
       "        2.2895143 ,  0.0741943 , -0.41046414,  1.438796  ,  0.19373988,\n",
       "        1.4294034 ,  1.5025262 ,  1.4849502 ,  1.5754777 ,  2.7793512 ,\n",
       "       -0.6885003 , -0.30154693, -1.708323  ,  1.1030879 , -2.2597387 ,\n",
       "        1.1909146 ,  2.4399316 ,  0.3990314 ,  0.904154  ,  0.5454401 ,\n",
       "       -1.3235748 , -0.64812386,  0.22390233,  0.9657619 , -0.47360668,\n",
       "       -0.10278235, -1.0679734 , -0.91414386,  0.92069   ,  0.3549338 ,\n",
       "        0.32858834,  0.84870636,  3.596926  , -1.6651102 ,  0.23658653,\n",
       "        1.0515738 ,  0.40531915, -0.773514  , -0.93460965, -0.3946274 ,\n",
       "       -1.5657727 ,  1.183652  ,  2.5277    ,  0.57700926,  1.7051374 ,\n",
       "       -1.8249958 , -2.0328498 ,  0.6617798 ,  0.85747904,  0.31782728,\n",
       "       -1.1660796 ,  0.32923874,  2.2055087 , -0.12782003,  2.0455444 ,\n",
       "       -0.1724252 ,  0.46001154,  1.559042  , -1.6152996 , -0.84242785,\n",
       "        0.7553168 ,  0.39734274,  0.07714175,  0.05610155,  0.32837135,\n",
       "        1.0220716 ,  1.3816743 ,  0.8049544 ,  0.28728685, -0.97610044,\n",
       "        0.8861181 , -0.01250968, -1.4845604 , -1.5236791 , -1.5451258 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_path = '/home/aiffel-dj31/aiffel/sentiment_classification/ko.bin'\n",
    "word2vec = Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj31/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬픔', 0.7216663360595703),\n",
       " ('행복', 0.6759077310562134),\n",
       " ('절망', 0.6468985676765442),\n",
       " ('기쁨', 0.6458414793014526),\n",
       " ('이별', 0.6334798336029053),\n",
       " ('추억', 0.6320937871932983),\n",
       " ('인생', 0.6216273307800293),\n",
       " ('애정', 0.6206068992614746),\n",
       " ('연인', 0.6186063289642334),\n",
       " ('유혹', 0.5965287685394287)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj31/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel-dj31/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 [==============================] - 8s 57us/sample - loss: 0.5322 - accuracy: 0.7259 - val_loss: 0.4221 - val_accuracy: 0.8090\n",
      "Epoch 2/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.3792 - accuracy: 0.8322 - val_loss: 0.3648 - val_accuracy: 0.8401\n",
      "Epoch 3/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.3261 - accuracy: 0.8600 - val_loss: 0.3556 - val_accuracy: 0.8427\n",
      "Epoch 4/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.2935 - accuracy: 0.8771 - val_loss: 0.3421 - val_accuracy: 0.8525\n",
      "Epoch 5/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.2679 - accuracy: 0.8901 - val_loss: 0.3447 - val_accuracy: 0.8529\n",
      "Epoch 6/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.2458 - accuracy: 0.9009 - val_loss: 0.3622 - val_accuracy: 0.8504\n",
      "Epoch 7/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.2261 - accuracy: 0.9098 - val_loss: 0.3773 - val_accuracy: 0.8508\n",
      "Epoch 8/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.2066 - accuracy: 0.9191 - val_loss: 0.3921 - val_accuracy: 0.8470\n",
      "Epoch 9/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.1874 - accuracy: 0.9284 - val_loss: 0.3940 - val_accuracy: 0.8492\n",
      "Epoch 10/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.1667 - accuracy: 0.9380 - val_loss: 0.4454 - val_accuracy: 0.8453\n",
      "Epoch 11/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.1499 - accuracy: 0.9453 - val_loss: 0.4609 - val_accuracy: 0.8424\n",
      "Epoch 12/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.1323 - accuracy: 0.9533 - val_loss: 0.4990 - val_accuracy: 0.8415\n",
      "Epoch 13/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.1182 - accuracy: 0.9593 - val_loss: 0.5579 - val_accuracy: 0.8398\n",
      "Epoch 14/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.1052 - accuracy: 0.9642 - val_loss: 0.5830 - val_accuracy: 0.8366\n",
      "Epoch 15/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.0971 - accuracy: 0.9674 - val_loss: 0.6135 - val_accuracy: 0.8394\n",
      "Epoch 16/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.0844 - accuracy: 0.9725 - val_loss: 0.6591 - val_accuracy: 0.8344\n",
      "Epoch 17/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.6802 - val_accuracy: 0.8330\n",
      "Epoch 18/20\n",
      "136182/136182 [==============================] - 6s 47us/sample - loss: 0.0718 - accuracy: 0.9763 - val_loss: 0.7707 - val_accuracy: 0.8323\n",
      "Epoch 19/20\n",
      "136182/136182 [==============================] - 6s 48us/sample - loss: 0.0658 - accuracy: 0.9785 - val_loss: 0.7791 - val_accuracy: 0.8352\n",
      "Epoch 20/20\n",
      "136182/136182 [==============================] - 7s 48us/sample - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.7690 - val_accuracy: 0.8326\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "검증 정확도 0.8326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49157/49157 - 2s - loss: 0.8013 - accuracy: 0.8271\n",
      "[0.8013117826645545, 0.82708466]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 0.8271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 루브릭 평가\n",
    "1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.\n",
    "\n",
    "lstm, conv, maxpooling 모델\n",
    "\n",
    "2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.\n",
    "\n",
    "gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함\n",
    "\n",
    "3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.\n",
    "\n",
    "정확도 82.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 총평고\n",
    "\n",
    "여태 노드 중 가장 어려웠던 노드였다. 자연어 처리의 개념이 아직도 잡히지 않은 상태인데 너무 세세한 것에 집중하느라 큰 틀을 보지 못했다. 하이퍼파라미터가 완벽히 어떤 영향을 끼치는지 깨닫지는 못했지만 느낌을 점점 잡아가고 있는 중이다. 이번에도 파이썬 코드를 보다 흡수하지 못한것이 아쉬웠고 노드 전에 문법부터 확실히 잡아두어야겠다는 생각이 들었다. 노드가 워낙 설명이 잘 되어 있지 않아 필요 개념을 일일이 찾아보면서 진행했는데 아직도 불분명한 것이 많아 자연어는 처음부터 다시 공부해야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
